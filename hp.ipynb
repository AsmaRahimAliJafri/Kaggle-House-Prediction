{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nimport matplotlib.pyplot as plt \nimport seaborn as sns\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom scipy.stats import norm\nfrom scipy import stats\nfrom scipy.stats import skew\nfrom scipy.stats.stats import pearsonr\n\npd.set_option('display.max_columns', 81)\n\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\n#print(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e6f086bfc87d72c0f5bc74c7c14c78878328c115",
        "scrolled": false
      },
      "cell_type": "code",
      "source": "#Preparing TRAINING DATASET\n# --------------- loading the training dataset as dfhouse ---------------\ndfhouse = pd.read_csv('../input/train.csv')\ndfhouse_raw = dfhouse.copy()     #saving a copy just in case\n#dfhouse.head()\n#dfhouse.describe()\n#dfhouse.info()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5669a1aadabb913b53a0637abc0234c0532aac16"
      },
      "cell_type": "markdown",
      "source": "\n**** Analysis of the predictor variable 'SalePrice**** \n"
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": "\n# ----------------- GRAPHICAL analysis of the predictor variable 'SalePrice' -----------------\nsaleprice = dfhouse['SalePrice']\nsaleprice_raw = dfhouse_raw['SalePrice']\nsns.distplot(saleprice)   #shows that the distribution has a right skew with a positive skew meaning that most of the houses were sold at lower prices thus hitting a low average\n#sns.swarmplot(dfhouse['SalePrice'])   #shows that most of the sales price range within 100K-400K with outliers etending beyond 400k\n#Inference: remove the outliers\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "928fd7f7412acfa953cce22095550b6268273108"
      },
      "cell_type": "code",
      "source": "print(dfhouse['SalePrice'].describe())\nprint(dfhouse['SalePrice'].skew())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2f3e7f1f965a3545fe831f53ffecb72e8904bfb2"
      },
      "cell_type": "markdown",
      "source": "* * * **Relationship between OverallQu and SalePrice **"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "42ab81cb9b7b2c71512670332dc2f3e97485f930"
      },
      "cell_type": "code",
      "source": "dfhouse['OverallQual'].describe()\nsns.jointplot(dfhouse.OverallQual, dfhouse['SalePrice'], data=dfhouse, kind=\"reg\")\n# INFERENCE: OverallQual and SalePrice share a linear relationship \n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2d95e314a115d4f4df2dc520c166b2d212595a5f"
      },
      "cell_type": "markdown",
      "source": "* * * **Relationship between YearBuilt and SalePrice **"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7f97a55d071cf14fef8d7d3ff6b315bb2747a08c"
      },
      "cell_type": "code",
      "source": "dfhouse['YearBuilt'].describe()\nsns.jointplot(dfhouse.YearBuilt, dfhouse['SalePrice'], data=dfhouse, kind=\"reg\")\n# INFERENCE: YearBuilt and SalePrice share an exponential relationship with the sale price proportionally increaing with the improvement in years.\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f9ed526159eeb6119c0c2f845e64163e80a8f238"
      },
      "cell_type": "markdown",
      "source": "* * * **Relationship between TotRmsAbvGrd and SalePrice **"
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "25aff77e311e4d18368f711c195ed6ad71cdeeee"
      },
      "cell_type": "code",
      "source": "dfhouse['TotRmsAbvGrd'].describe()\nsns.jointplot(dfhouse.TotRmsAbvGrd, dfhouse.SalePrice, data=dfhouse)\n#normal distribution with majority of values in the center, slightly left skewed",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "13f0ef53cfc6950a6e24385545919dd7eade3982"
      },
      "cell_type": "code",
      "source": "#scatter plot grlivarea/saleprice\nvar = 'GrLivArea'\ndata = pd.concat([dfhouse['SalePrice'], dfhouse[var]], axis=1)\ndata.plot.scatter(x=var, y='SalePrice', ylim=(0,800000));\n#shows that houses with minimal living area has lesser pricings\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a58784dbdcc264da1ce2acdfb2d2b65c922356be"
      },
      "cell_type": "code",
      "source": "#scatter plot totalbsmtsf/saleprice\nvar = 'TotalBsmtSF'\ndata = pd.concat([dfhouse['SalePrice'], dfhouse[var]], axis=1)\ndata.plot.scatter(x=var, y='SalePrice', ylim=(0,800000));\n#linear,proportional relationship",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5528d137a7801f55be832f951bed588be23d68b1"
      },
      "cell_type": "markdown",
      "source": "**Ceating a *CORRELATION* Matrix to deduce relationships between various features**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bf269c3f9fbf6ee258eeb1df11f06b4d4f253b9e",
        "scrolled": false
      },
      "cell_type": "code",
      "source": "#zoomed heatmap to consider the valueable features\n#saleprice correlation matrix\ndftemp = dfhouse_raw\ncorrmat = dftemp.corr()\n\nk=10\ni=1\nfor i in range(1,8,10):\n    f, ax = plt.subplots(figsize=(15, 10))\n    cols = corrmat.nlargest(k, 'SalePrice')['SalePrice'].index\n    cm = np.corrcoef(dftemp[cols].values.T)\n    sns.set(font_scale=1.25)\n    hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\n    plt.show()\n    dftemp = dftemp.drop(dftemp.columns[[i, i+10]], axis=1)\n    \n\n\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "73b08a5c995ae49c1d852e3e2e0c3413e3b597c7"
      },
      "cell_type": "markdown",
      "source": "**DATA CLEANING**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "10d2ccdb6a6827c6a5faa97ddbe453ace697718b"
      },
      "cell_type": "code",
      "source": "#deleting extreme outlier points from GrLvArea column\n\ndfhouse.sort_values(by = 'GrLivArea', ascending = False)[:2]\n\ndfhouse = dfhouse.drop(dfhouse[dfhouse['Id'] == 1299].index)\ndfhouse = dfhouse.drop(dfhouse[dfhouse['Id'] == 524].index)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e1193da21a7a00576d9394cbee1707c2c8193ef3",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "#applying log transformations on SalesPrice data to make sure that we have a normally didstributed feature\n\ndfhouse['SalePrice'] = np.log(dfhouse['SalePrice'])\nsns.distplot(dfhouse['SalePrice'], fit=norm)\nfig = plt.figure()\nres = stats.probplot(dfhouse['SalePrice'], plot=plt)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "58effd75e2def0d55c3414f82916fc1ebf6852d7"
      },
      "cell_type": "code",
      "source": "#applying log transformations on GrLivArea data to make sure that we have a normally didstributed feature\n#inspecting\nsns.distplot(dfhouse['GrLivArea'], fit=norm)\nfig = plt.figure()\nres = stats.probplot(dfhouse['GrLivArea'], plot=plt)\n\n#log transformation\ndfhouse['GrLivArea'] = np.log(dfhouse['GrLivArea'])\nsns.distplot(dfhouse['GrLivArea'], fit=norm)\nfig = plt.figure()\nres = stats.probplot(dfhouse['GrLivArea'], plot=plt)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4d61dffb61533228b9b247558edb9ff278d2abe7"
      },
      "cell_type": "code",
      "source": "#Since TotoalBsmtSF has a lot of zeros (houses having no basements) so applying log transformation to them will not produce correct results\n\n#create column for new variable (one is enough because it's a binary categorical feature)\n#if area>0 it gets 1, for area==0 it gets 0\n#df_train['HasBsmt'] = pd.Series(len(df_train['TotalBsmtSF']), index=df_train.index)\n#df_train['HasBsmt'] = 0 \n#df_train.loc[df_train['TotalBsmtSF']>0,'HasBsmt'] = 1\n\ndfhouse['HasBsmt'] = pd.Series(len(dfhouse['TotalBsmtSF']), index=dfhouse.index)\ndfhouse['HasBsmt'] = 0\ndfhouse.loc[dfhouse['TotalBsmtSF']>0, 'HasBsmt'] = 1\n\n#log transformation on non zero data\ndfhouse.loc[dfhouse['HasBsmt']==1,'TotalBsmtSF'] = np.log(dfhouse['TotalBsmtSF'])\n\n#histogram and normal probability plot\nsns.distplot(dfhouse[dfhouse['TotalBsmtSF']>0]['TotalBsmtSF'], fit=norm);\nfig = plt.figure()\nres = stats.probplot(dfhouse[dfhouse['TotalBsmtSF']>0]['TotalBsmtSF'], plot=plt)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c028436c8ccf238759580aa33c42e5d2b5da64f0"
      },
      "cell_type": "markdown",
      "source": "\n\n\n**COMPUTING AND FILLING IN MISSING VALUES**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "46e9550623ecffc61c7e201a4182b4a1be9505bb"
      },
      "cell_type": "code",
      "source": "#convert categorical variable into dummy\ndfhouse = pd.get_dummies(dfhouse)\nprint(dfhouse.ix[20, :])\n#filling in the missing values with the mean\ndfhouse = dfhouse.fillna(dfhouse.mean())\nprint(dfhouse.MSZoning_RL.dtype)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "241ece0aff21c6fc15ef6df9b2b535a13e365833"
      },
      "cell_type": "markdown",
      "source": "> **PREPARING CLEANING THE TEST DATA**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "278811cc02aaf7ace47eadea638102eb93e42e1f"
      },
      "cell_type": "code",
      "source": "dfhouseTest = pd.read_csv('../input/test.csv')\ndfhouseTest_raw = dfhouseTest.copy()\n\n#convert categorical variable into dummy\ndfhouseTest = pd.get_dummies(dfhouseTest)\nprint(dfhouse.ix[20, :])\n\n#filling in the missing values with the mean\ndfhouseTest = dfhouseTest.fillna(dfhouseTest.mean())\nprint(dfhouseTest.MSZoning_RL.dtype)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-output": true,
        "trusted": true,
        "_uuid": "f033fd439b57a4c91f61ec11e72c5a714dce0579"
      },
      "cell_type": "code",
      "source": "#dfhouse = dfhouse.drop(columns = ['SalePrice','Alley', 'FireplaceQu', 'PoolQC', 'Fence', 'MiscFeature'])\n#dfhouseTest = dfhouseTest.drop(columns = ['Alley', 'FireplaceQu', 'PoolQC', 'Fence', 'MiscFeature'])\ndfhouseTest.info()\n#dfhouseTest.shape()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3f3276e29131d4219c8e77bc3c13c2622f773b52"
      },
      "cell_type": "markdown",
      "source": "**LINEAR REGRESSION**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e56775b4ea3735681a54f66465ca02cedbf4ad93",
        "scrolled": true,
        "_kg_hide-output": true
      },
      "cell_type": "code",
      "source": "from sklearn.linear_model import LinearRegression\n#making the dimensions for the input and output test data\n\n#dropping inconsistent rows\ndfhouse_temp = dfhouse#.drop([1458, 1459]) #--- aleady dropped so commented to stop dropping further rows\ndfhouseTest_temp = dfhouseTest#.drop([1458])\nsaleprice = saleprice#.drop([1458, 1459])\n\n#dropping inconsistent columns\ncols_to_drop = dfhouse_temp.columns.difference(dfhouseTest_temp.columns)\ndfhouse_temp = dfhouse_temp.drop(columns = cols_to_drop)\n\n#printing to check the dimensions\nprint(dfhouse_temp.shape)\nprint(saleprice.shape)\nprint(dfhouseTest_temp.shape)\n\n#print(dfhouseTest_temp.dtypes)\n\n#fitting and observing scores\nregressor = LinearRegression()\nregressor.fit(dfhouse_temp, saleprice)\npredicted_result = regressor.predict(dfhouseTest_temp)\nprint(regressor.score(dfhouseTest_temp, predicted_result))\n#print(predicted_result.shape)\n\n# xtrain = np.array(dfhouse_temp).reshape(-1, 1)\n# ytrain = np.array(saleprice)\n# xtest = np.array(dfhouseTest_temp).reshape(-1, 1)\n# ytest = np.array(predicted_result)\n\n# print(xtrain.shape)\n# print(ytrain.shape)\n\n# #Visualizing the training Test Results \n# plt.scatter(xtrain, ytrain, color= 'red')\n# plt.plot(xtrain, regressor.predict(xtrain), color = 'blue')\n# plt.title (\"Visuals for Training Dataset\")\n# plt.xlabel(\"Space\")\n# plt.ylabel(\"Price\")\n# plt.show()\n\n# # #Visualizing the Test Results \n# plt.scatter(xtest, ytest, color= 'red')\n# plt.plot(xtrain, regressor.predict(xtrain), color = 'blue')\n# plt.title(\"Visuals for Test DataSet\")\n# plt.xlabel(\"Space\")\n# plt.ylabel(\"Price\")\n# plt.show()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9d0f70c63a66d755413d632dca5f16a1eab165bf"
      },
      "cell_type": "code",
      "source": "#submission code\nsubmission = pd.DataFrame({'train_sales':saleprice,'test_sales':predicted_result})\nsubmission.to_csv('submissionHouses.csv', index=False)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4e8dd90eb3c050b153aff494ef3bc315b85ae67a"
      },
      "cell_type": "code",
      "source": "#applying ridge regression to improve model\n# from sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Ridge\n\n#dropping inconsistent rows\ndfhouse_temp = dfhouse#.drop([1458, 1459]) #--- aleady dropped so commented to stop dropping further rows\ndfhouseTest_temp = dfhouseTest#.drop([1458])\nsaleprice = saleprice#.drop([1458, 1459])\n\n#dropping inconsistent columns\ncols_to_drop = dfhouse_temp.columns.difference(dfhouseTest_temp.columns)\ndfhouse_temp = dfhouse_temp.drop(columns = cols_to_drop)\n\n\n#converting df into nd numpy arrays \nX_train = dfhouse_temp.values\ny_train = saleprice.values\nX_test = dfhouseTest_temp.values\n\n#print(X_train.ndim())\n\n#for train set\nridreg = LinearRegression()\nridreg.fit(X_train, y_train)\n\nalpha1 = Ridge(alpha=0.01)\nalpha1.fit(X_train, y_train)\n\nalpha2 = Ridge(alpha = 100)\nalpha2.fit(X_train, y_train)\n\n#for test set\ny_test = ridreg.predict(X_test)\nridreg.fit(X_test, y_test)\n\nalpha1 = Ridge(alpha=0.01)\nalpha1.fit(X_test, y_test)\n\nalpha2 = Ridge(alpha = 100)\nalpha2.fit(X_test, y_test)\n\n#checking scores for each\nRidge_alpha1_score_train = alpha1.score(X_train, y_train)\nRidge_alpha1_score_test = alpha1.score(X_test, y_test)\nRidge_alpha2_score_train = alpha2.score(X_train, y_train)\nRidge_alpha2_score_test = alpha2.score(X_test, y_test)\n\n\nprint(\"ridge regression train score 1 alpha: \", Ridge_alpha1_score_train)\nprint(\"ridge regression test score 1 alpha: \", Ridge_alpha1_score_test)\nprint(\"ridge regression train score 2 alpha: \", Ridge_alpha2_score_train)\nprint(\"ridge regression test score 2 alpha: \", Ridge_alpha2_score_test)\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "024e007c748cbfff486fbd1aa3f634ce0b3206eb"
      },
      "cell_type": "code",
      "source": "# #implementing lasso regression\nfrom sklearn.linear_model import Lasso\n\nlasso1 = Lasso(alpha=1, max_iter = 10e5)\nlasso1.fit(X_train, y_train)\ntrain_score1 = lasso1.score(X_train, y_train)\ny_test1 = lasso1.predict(X_test)\ntest_score1 = lasso1.score(X_test, y_test1)\n\nprint(\"Alpha=1, train data score \",train_score1)\nprint(\"Alpha=1, test data score \",test_score1)\n\nlasso10 = Lasso(alpha=100, max_iter = 10e5)\nlasso10.fit(X_train, y_train)\ntrain_score10 = lasso10.score(X_train, y_train)\ny_test10 = lasso10.predict(X_test)\ntest_score10 = lasso10.score(X_test, y_test10)\n\nprint(\"Alpha=10, train data score \",train_score10)\nprint(\"Alpha=10, test data score \",test_score10)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "67a1a26d1fef6d874e706af184b2b9c3b34b5864"
      },
      "cell_type": "code",
      "source": "dfhouseTest_temp.to_csv('housePredTestFile.csv',index=False)",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}